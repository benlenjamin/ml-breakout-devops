{
    "name": "root",
    "gauges": {
        "Paddle.Policy.Entropy.mean": {
            "value": 1.0928280353546143,
            "min": 1.0928280353546143,
            "max": 1.4078975915908813,
            "count": 50
        },
        "Paddle.Policy.Entropy.sum": {
            "value": 10928.2802734375,
            "min": 10903.62109375,
            "max": 14083.2001953125,
            "count": 50
        },
        "Paddle.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 37.47450980392157,
            "max": 999.0,
            "count": 50
        },
        "Paddle.Environment.EpisodeLength.sum": {
            "value": 9990.0,
            "min": 9119.0,
            "max": 10891.0,
            "count": 50
        },
        "Paddle.Step.mean": {
            "value": 499955.0,
            "min": 9939.0,
            "max": 499955.0,
            "count": 50
        },
        "Paddle.Step.sum": {
            "value": 499955.0,
            "min": 9939.0,
            "max": 499955.0,
            "count": 50
        },
        "Paddle.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.988875687122345,
            "min": -0.8444989919662476,
            "max": 1.003451943397522,
            "count": 50
        },
        "Paddle.Policy.ExtrinsicValueEstimate.sum": {
            "value": 158.22010803222656,
            "min": -201.83526611328125,
            "max": 160.55230712890625,
            "count": 50
        },
        "Paddle.Environment.CumulativeReward.mean": {
            "value": 9.99999886751175,
            "min": -0.6252549381817089,
            "max": 9.99999886751175,
            "count": 50
        },
        "Paddle.Environment.CumulativeReward.sum": {
            "value": 99.99998867511749,
            "min": -159.44000923633575,
            "max": 103.22998780012131,
            "count": 50
        },
        "Paddle.Policy.ExtrinsicReward.mean": {
            "value": 9.99999886751175,
            "min": -0.6252549381817089,
            "max": 9.99999886751175,
            "count": 50
        },
        "Paddle.Policy.ExtrinsicReward.sum": {
            "value": 99.99998867511749,
            "min": -159.44000923633575,
            "max": 103.22998780012131,
            "count": 50
        },
        "Paddle.Losses.PolicyLoss.mean": {
            "value": 0.24486875847903775,
            "min": 0.23527836806369307,
            "max": 0.2541770871920492,
            "count": 50
        },
        "Paddle.Losses.PolicyLoss.sum": {
            "value": 19.58950067832302,
            "min": 18.35171270896806,
            "max": 20.137879016914617,
            "count": 50
        },
        "Paddle.Losses.ValueLoss.mean": {
            "value": 0.007222927109469264,
            "min": 5.9139966034196495e-05,
            "max": 0.4691078667385769,
            "count": 50
        },
        "Paddle.Losses.ValueLoss.sum": {
            "value": 0.5778341687575411,
            "min": 0.00473119728273572,
            "max": 37.059521472347576,
            "count": 50
        },
        "Paddle.Policy.LearningRate.mean": {
            "value": 3.0198989934000017e-06,
            "min": 3.0198989934000017e-06,
            "max": 0.00029701906196925604,
            "count": 50
        },
        "Paddle.Policy.LearningRate.sum": {
            "value": 0.00024159191947200012,
            "min": 0.00024159191947200012,
            "max": 0.024355563081478997,
            "count": 50
        },
        "Paddle.Policy.Epsilon.mean": {
            "value": 0.10100660000000002,
            "min": 0.10100660000000002,
            "max": 0.19900635365853664,
            "count": 50
        },
        "Paddle.Policy.Epsilon.sum": {
            "value": 8.080528000000001,
            "min": 8.080528000000001,
            "max": 16.318521000000004,
            "count": 50
        },
        "Paddle.Policy.Beta.mean": {
            "value": 0.0005000000000000001,
            "min": 0.0005000000000000001,
            "max": 0.0005000000000000001,
            "count": 50
        },
        "Paddle.Policy.Beta.sum": {
            "value": 0.04000000000000001,
            "min": 0.038500000000000006,
            "max": 0.04100000000000001,
            "count": 50
        },
        "Paddle.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 50
        },
        "Paddle.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 50
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1732296174",
        "python_version": "3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]",
        "command_line_arguments": "/opt/anaconda3/envs/mlagents/bin/mlagents-learn agent-training-configs/config_v0.yaml --run-id=my_run_id --train --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1732297944"
    },
    "total": 1770.6331396671012,
    "count": 1,
    "self": 0.006424750201404095,
    "children": {
        "run_training.setup": {
            "total": 0.01823370810598135,
            "count": 1,
            "self": 0.01823370810598135
        },
        "TrainerController.start_learning": {
            "total": 1770.6084812087938,
            "count": 1,
            "self": 3.8694317624904215,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.14086683280766,
                    "count": 1,
                    "self": 11.14086683280766
                },
                "TrainerController.advance": {
                    "total": 1755.5810312386602,
                    "count": 501171,
                    "self": 3.371259013656527,
                    "children": {
                        "env_step": {
                            "total": 1542.3180933031254,
                            "count": 501171,
                            "self": 1415.3640985977836,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 124.14603320322931,
                                    "count": 501171,
                                    "self": 9.949962254613638,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 114.19607094861567,
                                            "count": 500019,
                                            "self": 114.19607094861567
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.807961502112448,
                                    "count": 501171,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1754.3155098017305,
                                            "count": 501171,
                                            "is_parallel": true,
                                            "self": 522.9740139306523,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0023771668784320354,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00023445812985301018,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0021427087485790253,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0021427087485790253
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1231.3391187041998,
                                                    "count": 501171,
                                                    "is_parallel": true,
                                                    "self": 11.684296234510839,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 26.9815779235214,
                                                            "count": 501171,
                                                            "is_parallel": true,
                                                            "self": 26.9815779235214
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1159.9588096458465,
                                                            "count": 501171,
                                                            "is_parallel": true,
                                                            "self": 1159.9588096458465
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 32.714434900321066,
                                                            "count": 501171,
                                                            "is_parallel": true,
                                                            "self": 14.523684362880886,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 18.19075053744018,
                                                                    "count": 1002342,
                                                                    "is_parallel": true,
                                                                    "self": 18.19075053744018
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 209.89167892187834,
                            "count": 501171,
                            "self": 4.608282616361976,
                            "children": {
                                "process_trajectory": {
                                    "total": 13.873421309981495,
                                    "count": 501171,
                                    "self": 13.779214851558208,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.09420645842328668,
                                            "count": 1,
                                            "self": 0.09420645842328668
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 191.40997499553487,
                                    "count": 3963,
                                    "self": 28.15784377977252,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 163.25213121576235,
                                            "count": 141534,
                                            "self": 163.25213121576235
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.3294782042503357e-07,
                    "count": 1,
                    "self": 3.3294782042503357e-07
                },
                "TrainerController._save_models": {
                    "total": 0.017151041887700558,
                    "count": 1,
                    "self": 0.0005755419842898846,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.016575499903410673,
                            "count": 1,
                            "self": 0.016575499903410673
                        }
                    }
                }
            }
        }
    }
}